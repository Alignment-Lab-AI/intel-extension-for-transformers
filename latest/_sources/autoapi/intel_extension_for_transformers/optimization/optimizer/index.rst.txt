:py:mod:`intel_extension_for_transformers.optimization.optimizer`
=================================================================

.. py:module:: intel_extension_for_transformers.optimization.optimizer

.. autoapi-nested-parse::

   Optimization: provides the orchestrate optimizer for Pytorch.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   intel_extension_for_transformers.optimization.optimizer.Orchestrate_optimizer
   intel_extension_for_transformers.optimization.optimizer.NoTrainerOptimizer




.. py:class:: Orchestrate_optimizer(model, components: Optional[List[neural_compressor.experimental.Component]] = [], eval_func: Optional[Callable] = None, train_func: Optional[Callable] = None)

   Orchestrate_optimizer aggregates and orchestrates components such as Quantization, Pruning and Distillation.

   .. py:method:: fit()

      Run the scheduler.



.. py:class:: NoTrainerOptimizer(model, output_dir: Optional[str] = 'saved_results')

   Optimizer without using Trainer.

   .. py:property:: eval_func

      Get the evaluation function.

   .. py:property:: train_func

      Get the train function.

   .. py:property:: calib_func

      Get the calib function.

   .. py:property:: provider

      Get the provider.

   .. py:property:: calib_dataloader

      Get the calibration dataloader.

   .. py:method:: init_quantizer(quant_config, provider: str = Provider.INC.value)

      Init a Quantization object with config.


   .. py:method:: quantize(quant_config: intel_extension_for_transformers.optimization.QuantizationConfig = None, provider: str = Provider.INC.value, eval_func: Optional[Callable] = None, train_func: Optional[Callable] = None, calib_func: Optional[Callable] = None, calib_dataloader=None)

      Prepare for invoking the _inc_quantize function.


   .. py:method:: init_pruner(pruning_config=None, provider: str = Provider.INC.value)

      Init a Pruning object with config.


   .. py:method:: prune(pruning_config=None, provider: str = Provider.INC.value, eval_func: Optional[Callable] = None, train_func: Optional[Callable] = None)

      Do the pruning.


   .. py:method:: init_distiller(distillation_config, teacher_model, provider: str = Provider.INC.value)

      Init a Distillation object with config and the teacher model.


   .. py:method:: distill(distillation_config, teacher_model, provider: str = Provider.INC.value, eval_func: Optional[Callable] = None, train_func: Optional[Callable] = None)

      Do the distillation.



